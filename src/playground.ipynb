{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_precision = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_muris_path = \"../datasets/tabula_muris_whole/\"\n",
    "all_counts_path = \"brain_mouse_matrix_all_counts.csv\"\n",
    "all_data_path = \"brain_mouse_matrix_all_data.csv\"\n",
    "all_scaled_path = \"brain_mouse_matrix_all_scale_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = pd.read_csv(tabula_muris_path + all_counts_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data =  pd.read_csv(tabula_muris_path + all_data_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scaled =  pd.read_csv(tabula_muris_path + all_scaled_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_ID</th>\n",
       "      <th>0610005C13Rik</th>\n",
       "      <th>0610007C21Rik</th>\n",
       "      <th>0610007L01Rik</th>\n",
       "      <th>0610007N19Rik</th>\n",
       "      <th>0610007P08Rik</th>\n",
       "      <th>0610007P14Rik</th>\n",
       "      <th>0610007P22Rik</th>\n",
       "      <th>0610008F07Rik</th>\n",
       "      <th>0610009B14Rik</th>\n",
       "      <th>...</th>\n",
       "      <th>Zxdc</th>\n",
       "      <th>Zyg11a</th>\n",
       "      <th>Zyg11b</th>\n",
       "      <th>Zyx</th>\n",
       "      <th>Zzef1</th>\n",
       "      <th>Zzz3</th>\n",
       "      <th>a</th>\n",
       "      <th>l7Rn6</th>\n",
       "      <th>zsGreen-transgene</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1.B003290.3_38_F.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1.B003728.3_56_F.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1.MAA000560.3_10_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1.MAA000564.3_10_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1.MAA000923.3_9_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CELL_ID  0610005C13Rik  0610007C21Rik  0610007L01Rik  \\\n",
       "0    A1.B003290.3_38_F.1.1              0            125             16   \n",
       "1    A1.B003728.3_56_F.1.1              0              0              0   \n",
       "2  A1.MAA000560.3_10_M.1.1              0            348              0   \n",
       "3  A1.MAA000564.3_10_M.1.1              0             41             36   \n",
       "4   A1.MAA000923.3_9_M.1.1              0             53              0   \n",
       "\n",
       "   0610007N19Rik  0610007P08Rik  0610007P14Rik  0610007P22Rik  0610008F07Rik  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0            324              0              0   \n",
       "2              0              0              5              0              0   \n",
       "3              0              0             24              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   0610009B14Rik  ...  Zxdc  Zyg11a  Zyg11b  Zyx  Zzef1  Zzz3  a  l7Rn6  \\\n",
       "0              0  ...     0       0       0    0      0     0  0     54   \n",
       "1              0  ...     0       0       0    0      0     0  0      0   \n",
       "2              0  ...     0       0       0    0    195     0  0    113   \n",
       "3              0  ...     0       0       0  125      0     1  0      0   \n",
       "4              0  ...     0       0      81    0      0     0  0      0   \n",
       "\n",
       "   zsGreen-transgene  annotation  \n",
       "0                  0           1  \n",
       "1                  0           1  \n",
       "2                  0           6  \n",
       "3                  0           4  \n",
       "4                  0           1  \n",
       "\n",
       "[5 rows x 23343 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_counts.corr()['annotation'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normalize_data(data, scale=1000000.0):\n",
    "    data_row_sums = np.sum(data, axis=1).reshape(-1, 1)\n",
    "    return np.log(1 + scale * data / data_row_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "- one hot encoding of y\n",
    "- Log normalize all data\n",
    "- Split test and train data (stratified by y)\n",
    "- Scale data by normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_counts.iloc[:,1:-1].to_numpy(dtype=type_precision)\n",
    "y_num = all_counts.iloc[:, -1].to_numpy(dtype=type_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBin = preprocessing.LabelBinarizer()\n",
    "labelBin.fit(y_num)\n",
    "y = labelBin.transform(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = log_normalize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = model_selection.train_test_split(X, y, test_size=0.33, stratify=y, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2278, 23341)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1123, 23341)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction #1 - PCA\n",
    "- TODO: pick different number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train_val)\n",
    "X_train_val_prepared_PCA = pca.transform(X_train_val)\n",
    "X_test_prepared_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: 0.1484992802143097\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance: {}\".format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2278, 12), (1123, 12))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val_prepared_PCA.shape, X_test_prepared_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999326, 1.0000049 , 1.0000058 , ..., 1.0000243 , 1.0000169 ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.var(X_train_val, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction #2 - Autoencoder\n",
    "- Problem: Autoencoder loss not decreasing at all\n",
    "- Solution: increase number of layers and neurons per layer, train it on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature_num = X_train_val.shape[1]\n",
    "encoding_dim = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23341"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_feature_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_normalized = (X_train_val-np.min(X_train_val))/(np.max(X_train_val)-np.min(X_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 23341)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = Input(shape=(base_feature_num,))\n",
    "\n",
    "# Encoder Layers\n",
    "encoded1 = Dense(1000, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(300, activation = 'relu')(encoded1)\n",
    "encoded3 = Dense(encoding_dim, activation = 'relu')(encoded2)\n",
    "\n",
    "# Decoder Layers    \n",
    "decoded1 = Dense(300, activation = 'relu')(encoded3)\n",
    "decoded2 = Dense(1000, activation = 'relu')(decoded1)\n",
    "decoded3 = Dense(base_feature_num, activation = 'sigmoid')(decoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs=input_dim, outputs=decoded3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 23341)             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1000)              23342000  \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 300)               300300    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 12)                3612      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 300)               3900      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1000)              301000    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 23341)             23364341  \n",
      "=================================================================\n",
      "Total params: 47,315,153\n",
      "Trainable params: 47,315,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.fit(X_train_val_normalized,\n",
    "#                 X_train_val_normalized,\n",
    "#                 nb_epoch=1,\n",
    "#                 batch_size=32,\n",
    "#                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "- models: gradient boosting, NN, kNN(k=30 za pocetak), SVM, random forest \n",
    "- clean data\n",
    "- pick dimension reduction method\n",
    "- pick model\n",
    "- split train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data):\n",
    "    X_train, y_train = data\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, name):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print('Model: {}'.format(name))\n",
    "    print('Train set report: \\n{}'.format(metrics.classification_report(y_train, y_train_pred)))\n",
    "    print('Validation set report: \\n{}'.format(metrics.classification_report(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(model, data, name):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    y_train_pred = np.argmax(model.predict(X_train), axis=1) + 1\n",
    "    y_val_pred = np.argmax(model.predict(X_val), axis=1) + 1\n",
    "    print('Model: {}'.format(name))\n",
    "    print('Train set report: \\n{}'.format(metrics.classification_report(y_train, y_train_pred)))\n",
    "    print('Validation set report: \\n{}'.format(metrics.classification_report(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_evaluation(model, X, y, number_of_folds, error_function):\n",
    "    y_predicted = np.empty(y.size)\n",
    "    \n",
    "    ix = np.arange(0, X.shape[0]) % number_of_folds\n",
    "    \n",
    "    for i in range(number_of_folds):\n",
    "        X_train = X[ix != i, :]\n",
    "        y_train = y[ix != i]\n",
    "        \n",
    "        y_test = y[ix == i]\n",
    "        X_test = X[ix == i, :]\n",
    "        \n",
    "        model.fit(X_train, X_train)\n",
    "        y_predicted[ix == i] = model.predict(X_test)\n",
    "        \n",
    "    return error_function(y, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_selection(X, y, number_of_folds, error_function, configure_model, configs):\n",
    "    errors = []\n",
    "    \n",
    "    for c in configs:\n",
    "        model = configure_model(c)\n",
    "        error = cross_validation_evaluation(model, X, y, number_of_folds, error_function)\n",
    "        errors.append(error)\n",
    "        \n",
    "    errors = np.array(errors)\n",
    "    c_best = configs[np.argmin(errors)]\n",
    "    \n",
    "    model = configure_model(c_best)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model, X_test, y_test_num):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    f1_score = metrics.f1_score(y_test_num, y_test_pred, average='weighted')\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score_nn(model, X_test, y_test_num):\n",
    "    y_test_pred = np.argmax(model.predict(X_test), axis=1) + 1\n",
    "    f1_score = metrics.f1_score(y_test_num, y_test_pred, average='weighted')\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_score(model, X_test, y_test_num):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    acc_score = metrics.accuracy_score(y_test_num, y_test_pred)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_score_nn(model, X_test, y_test_num):\n",
    "    y_test_pred = np.argmax(model.predict(X_test), axis=1) + 1\n",
    "    acc_score = metrics.accuracy_score(y_test_num, y_test_pred)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_by_class(model, X_test, y_test_num):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    matrix = confusion_matrix(y_test_num, y_test_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_by_class_nn(model, X_test, y_test_num):\n",
    "    y_test_pred = np.argmax(model.predict(X_test), axis=1) + 1\n",
    "    matrix = confusion_matrix(y_test_num, y_test_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc_by_class(arr):\n",
    "    for i in arr:\n",
    "        print(round(i*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_bin, y_val_bin = model_selection.train_test_split(X_train_val_prepared_PCA, y_train_val, test_size=0.33, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num = labelBin.inverse_transform(y_train_bin)\n",
    "y_val_num = labelBin.inverse_transform(y_val_bin)\n",
    "y_test_num = labelBin.inverse_transform(y_test)\n",
    "y_train_val_num = labelBin.inverse_transform(y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train/val shape:  (1526, 12) (752, 12)\n",
      "y encoded train/val shape:  (1526, 7) (752, 7)\n",
      "y train/val shape:  (1526,) (752,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train/val shape: \", X_train.shape, X_val.shape)\n",
    "print(\"y encoded train/val shape: \", y_train_bin.shape, y_val_bin.shape)\n",
    "print(\"y train/val shape: \", y_train_num.shape, y_val_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multionomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logistic_regression(conf):\n",
    "    return LogisticRegression(C = conf, class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = configure_logistic_regression(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=12, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      0.98      0.97       194\n",
      "        2.0       0.80      0.67      0.73        18\n",
      "        3.0       0.99      1.00      0.99        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      0.99      0.99       706\n",
      "        7.0       0.97      1.00      0.98        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.97      0.95        95\n",
      "        2.0       0.43      0.33      0.38         9\n",
      "        3.0       0.97      1.00      0.99        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.97      1.00      0.98        62\n",
      "        6.0       1.00      0.98      0.99       348\n",
      "        7.0       0.96      0.98      0.97        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr_clf, (X_train, X_val, y_train_num, y_val_num), \"Logistic regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating  best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.98      0.96       289\n",
      "        2.0       0.59      0.48      0.53        27\n",
      "        3.0       0.99      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       0.99      1.00      1.00       188\n",
      "        6.0       1.00      0.99      0.99      1054\n",
      "        7.0       0.97      0.99      0.98       136\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.91      0.97      0.94       143\n",
      "        2.0       0.43      0.23      0.30        13\n",
      "        3.0       0.96      1.00      0.98        51\n",
      "        4.0       0.99      0.99      0.99       236\n",
      "        5.0       0.98      0.99      0.98        93\n",
      "        6.0       1.00      0.98      0.99       520\n",
      "        7.0       0.97      1.00      0.99        67\n",
      "\n",
      "avg / total       0.97      0.98      0.97      1123\n",
      "\n",
      "Model: Logistic Regression\n",
      "Weighted F1-score:  0.9734543282348008\n",
      "Accuracy:  0.97506678539626\n",
      "96.5\n",
      "23.08\n",
      "100.0\n",
      "98.73\n",
      "98.92\n",
      "98.27\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C = 12, class_weight='balanced')\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Logistic regression\")\n",
    "print(\"Model: Logistic Regression\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_clf = ensemble.GradientBoostingClassifier(n_estimators=600, max_depth=2, learning_rate=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_clf = train_model(grad_boost_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Grad Boost\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.98      0.99      0.99       194\n",
      "        2.0       1.00      0.78      0.88        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       0.99      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.98      0.95        95\n",
      "        2.0       1.00      0.22      0.36         9\n",
      "        3.0       1.00      0.97      0.99        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.97      1.00      0.98        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grad_boost_clf, (X_train, X_val, y_train_num, y_val_num), \"Grad Boost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Grad Boost regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.96      1.00      0.98       289\n",
      "        2.0       1.00      0.59      0.74        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       0.99      1.00      0.99       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.92      0.98      0.95       143\n",
      "        2.0       1.00      0.15      0.27        13\n",
      "        3.0       1.00      1.00      1.00        51\n",
      "        4.0       0.99      0.99      0.99       236\n",
      "        5.0       0.98      0.95      0.96        93\n",
      "        6.0       0.98      0.99      0.99       520\n",
      "        7.0       0.99      0.99      0.99        67\n",
      "\n",
      "avg / total       0.98      0.98      0.97      1123\n",
      "\n",
      "Model: Grad Boost\n",
      "Weighted F1-score:  0.9734347392227835\n",
      "Accuracy:  0.9768477292965272\n",
      "97.9\n",
      "15.38\n",
      "100.0\n",
      "98.73\n",
      "94.62\n",
      "99.42\n",
      "98.51\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.GradientBoostingClassifier(n_estimators=600, max_depth=2, learning_rate=0.006)\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Grad Boost regression\")\n",
    "print(\"Model: Grad Boost\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786557151410951 (4, 300)\n"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0\n",
    "best_params = (0,0,0)\n",
    "\n",
    "for max_depth in range(2,5):\n",
    "    for n_estimators in range(300, 800, 100):\n",
    "        for learning_rate in [0.1, 0.33, 1, 3.33, 10]:\n",
    "            ada_boost_clf = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=max_depth),\n",
    "                                                        algorithm='SAMME',\n",
    "                                                        n_estimators=n_estimators, \n",
    "                                                        learning_rate=0.5)\n",
    "\n",
    "            ada_boost_clf = train_model(ada_boost_clf, (X_train, y_train_num))\n",
    "            #y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = ada_boost_clf.predict(X_val)\n",
    "            curr_f1_score = metrics.f1_score(y_val_num, y_val_pred, average='weighted')\n",
    "            if curr_f1_score > best_f1_score:\n",
    "                best_f1_score = curr_f1_score\n",
    "                best_params = (max_depth, n_estimators, learning_rate)\n",
    "\n",
    "print(best_f1_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_f1_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an AdaBoosted decision tree\n",
    "ada_boost_clf = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=4),\n",
    "                                            algorithm=\"SAMME\",\n",
    "                                            n_estimators=300,\n",
    "                                            learning_rate=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_clf = train_model(ada_boost_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       194\n",
      "        2.0       1.00      1.00      1.00        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.97      0.95        95\n",
      "        2.0       0.60      0.33      0.43         9\n",
      "        3.0       1.00      0.97      0.99        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.97      1.00      0.98        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.96      1.00      0.98        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ada_boost_clf, (X_train, X_val, y_train_num, y_val_num), \"Ada Boost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       289\n",
      "        2.0       1.00      1.00      1.00        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       1.00      1.00      1.00       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.97      0.97      0.97       143\n",
      "        2.0       0.73      0.62      0.67        13\n",
      "        3.0       1.00      0.98      0.99        51\n",
      "        4.0       0.99      0.99      0.99       236\n",
      "        5.0       0.99      0.99      0.99        93\n",
      "        6.0       0.99      0.99      0.99       520\n",
      "        7.0       0.98      0.97      0.98        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n",
      "Model: ADA Boost\n",
      "Weighted F1-score:  0.9836857175877501\n",
      "Accuracy:  0.9839715048975958\n",
      "97.2\n",
      "61.54\n",
      "98.04\n",
      "99.15\n",
      "98.92\n",
      "99.42\n",
      "97.01\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=4),\n",
    "                                    algorithm=\"SAMME\",\n",
    "                                    n_estimators=300,\n",
    "                                    learning_rate=0.5)\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Ada Boost regression\")\n",
    "print(\"Model: ADA Boost\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - pip install xgboost\n",
    "## -- import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786557151410951 (3, 200, 0.1, 'gbtree')\n"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0\n",
    "best_params = (0,0,0)\n",
    "\n",
    "for max_depth in range(3,5):\n",
    "    for n_estimators in range(200, 500, 100):\n",
    "        for learning_rate in [0.01, 0.033, 0.1, 0.33, 1]:\n",
    "            for booster in ['gbtree', 'gblinear', 'dart']:\n",
    "                xgb_clf = xgb.XGBClassifier(objective='multi:softprob', \n",
    "                                            max_depth=max_depth,\n",
    "                                            n_estimators=n_estimators,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            booster=booster)\n",
    "\n",
    "                xgb_clf = train_model(ada_boost_clf, (X_train, y_train_num))\n",
    "                #y_train_pred = model.predict(X_train)\n",
    "                y_val_pred = xgb_clf.predict(X_val)\n",
    "                curr_f1_score = metrics.f1_score(y_val_num, y_val_pred, average='weighted')\n",
    "                if curr_f1_score > best_f1_score:\n",
    "                    best_f1_score = curr_f1_score\n",
    "                    best_params = (max_depth, n_estimators, learning_rate, booster)\n",
    "\n",
    "print(best_f1_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softprob', \n",
    "                            max_depth=5, \n",
    "                            n_estimators=500, \n",
    "                            learning_rate=0.01,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=1,\n",
    "                            gamma=1)\n",
    "                            #booster='dart'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = train_model(xgb_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9808404145191841"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = xgb_clf.predict(X_val)\n",
    "curr_f1_score = metrics.f1_score(y_val_num, y_val_pred, average='weighted')\n",
    "curr_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.98      1.00      0.99       194\n",
      "        2.0       1.00      0.83      0.91        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       0.99      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.99      0.96        95\n",
      "        2.0       1.00      0.33      0.50         9\n",
      "        3.0       1.00      0.97      0.99        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.98      1.00      0.99        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb_clf, (X_train, X_val, y_train_num, y_val_num), \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.99      1.00      0.99       289\n",
      "        2.0       1.00      0.89      0.94        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       0.99      1.00      1.00       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.99      0.96       143\n",
      "        2.0       0.83      0.38      0.53        13\n",
      "        3.0       1.00      1.00      1.00        51\n",
      "        4.0       1.00      0.99      0.99       236\n",
      "        5.0       0.98      0.99      0.98        93\n",
      "        6.0       0.99      0.99      0.99       520\n",
      "        7.0       0.97      0.97      0.97        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n",
      "Model: XGBoost\n",
      "Weighted F1-score:  0.979945094619379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.981300089047195\n",
      "98.6\n",
      "38.46\n",
      "100.0\n",
      "99.15\n",
      "98.92\n",
      "98.85\n",
      "97.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='multi:softprob', \n",
    "                            max_depth=5, \n",
    "                            n_estimators=500, \n",
    "                            learning_rate=0.01,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=1,\n",
    "                            gamma=1)\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Ada Boost regression\")\n",
    "print(\"Model: XGBoost\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "\n",
    "\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = X_train.shape[-1]\n",
    "output_size = y_train_bin.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_clf = Sequential()\n",
    "nn_clf.add(Dense(units=15, input_dim=number_of_features, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=output_size, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_166 (Dense)            (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 1,987\n",
      "Trainable params: 1,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1526 samples, validate on 752 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6717 - acc: 0.5990 - val_loss: 0.5206 - val_acc: 0.7449\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3292 - acc: 0.8707 - val_loss: 0.2194 - val_acc: 0.9043\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1911 - acc: 0.9078 - val_loss: 0.1791 - val_acc: 0.9107\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1618 - acc: 0.9188 - val_loss: 0.1554 - val_acc: 0.9291\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1369 - acc: 0.9400 - val_loss: 0.1275 - val_acc: 0.9441\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1042 - acc: 0.9565 - val_loss: 0.0936 - val_acc: 0.9652\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0724 - acc: 0.9802 - val_loss: 0.0680 - val_acc: 0.9821\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0537 - acc: 0.9846 - val_loss: 0.0555 - val_acc: 0.9837\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0443 - acc: 0.9855 - val_loss: 0.0467 - val_acc: 0.9854\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0392 - acc: 0.9867 - val_loss: 0.0413 - val_acc: 0.9863\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0341 - acc: 0.9879 - val_loss: 0.0386 - val_acc: 0.9858\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0270 - acc: 0.9890 - val_loss: 0.0292 - val_acc: 0.9932\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0214 - acc: 0.9943 - val_loss: 0.0243 - val_acc: 0.9932\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0243 - val_acc: 0.9930\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0241 - val_acc: 0.9945\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0267 - val_acc: 0.9932\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0252 - val_acc: 0.9932\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0241 - val_acc: 0.9939\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0122 - acc: 0.9955 - val_loss: 0.0206 - val_acc: 0.9949\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0209 - val_acc: 0.9951\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0108 - acc: 0.9960 - val_loss: 0.0226 - val_acc: 0.9943\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0100 - acc: 0.9964 - val_loss: 0.0214 - val_acc: 0.9954\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0100 - acc: 0.9971 - val_loss: 0.0217 - val_acc: 0.9953\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0243 - val_acc: 0.9951\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0101 - acc: 0.9964 - val_loss: 0.0220 - val_acc: 0.9951\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0092 - acc: 0.9969 - val_loss: 0.0214 - val_acc: 0.9949\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0085 - acc: 0.9969 - val_loss: 0.0221 - val_acc: 0.9953\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0203 - val_acc: 0.9947\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0089 - acc: 0.9968 - val_loss: 0.0207 - val_acc: 0.9953\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0221 - val_acc: 0.9947\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0241 - val_acc: 0.9945\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0223 - val_acc: 0.9945\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0220 - val_acc: 0.9951\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0243 - val_acc: 0.9953\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0214 - val_acc: 0.9939\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0228 - val_acc: 0.9947\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0241 - val_acc: 0.9954\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0209 - val_acc: 0.9956\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0240 - val_acc: 0.9953\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0204 - val_acc: 0.9954\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0224 - val_acc: 0.9956\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0216 - val_acc: 0.9953\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0198 - val_acc: 0.9954\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0215 - val_acc: 0.9956\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0224 - val_acc: 0.9954\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0203 - val_acc: 0.9954\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0201 - val_acc: 0.9958\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0202 - val_acc: 0.9954\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0213 - val_acc: 0.9954\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0204 - val_acc: 0.9960\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0210 - val_acc: 0.9956\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0212 - val_acc: 0.9953\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0198 - val_acc: 0.9962\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0226 - val_acc: 0.9958\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0202 - val_acc: 0.9962\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0045 - acc: 0.9992 - val_loss: 0.0210 - val_acc: 0.9962\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0232 - val_acc: 0.9951\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0207 - val_acc: 0.9958\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0238 - val_acc: 0.9958\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0220 - val_acc: 0.9960\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0217 - val_acc: 0.9960\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0205 - val_acc: 0.9958\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0141 - acc: 0.9971 - val_loss: 0.0589 - val_acc: 0.9922\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0184 - acc: 0.9969 - val_loss: 0.0377 - val_acc: 0.9937\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0291 - val_acc: 0.9932\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0246 - val_acc: 0.9954\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0208 - val_acc: 0.9958\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0070 - acc: 0.9992 - val_loss: 0.0203 - val_acc: 0.9964\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0199 - val_acc: 0.9962\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0204 - val_acc: 0.9966\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0228 - val_acc: 0.9962\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0205 - val_acc: 0.9966\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0203 - val_acc: 0.9964\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0072 - acc: 0.9991 - val_loss: 0.0275 - val_acc: 0.9956\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0215 - val_acc: 0.9956\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0065 - acc: 0.9993 - val_loss: 0.0198 - val_acc: 0.9960\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0200 - val_acc: 0.9966\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0207 - val_acc: 0.9964\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0218 - val_acc: 0.9960\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0063 - acc: 0.9992 - val_loss: 0.0208 - val_acc: 0.9960\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0236 - val_acc: 0.9958\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0206 - val_acc: 0.9964\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0071 - acc: 0.9989 - val_loss: 0.0209 - val_acc: 0.9962\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0208 - val_acc: 0.9958\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0211 - val_acc: 0.9966\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0109 - acc: 0.9976 - val_loss: 0.0341 - val_acc: 0.9943\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0122 - acc: 0.9973 - val_loss: 0.0218 - val_acc: 0.9958\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0218 - val_acc: 0.9958\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0241 - val_acc: 0.9960\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0198 - val_acc: 0.9968\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0210 - val_acc: 0.9966\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0211 - val_acc: 0.9970\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0283 - val_acc: 0.9956\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0200 - val_acc: 0.9966\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0214 - val_acc: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0225 - val_acc: 0.9962\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0273 - val_acc: 0.9954\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0212 - val_acc: 0.9968\n"
     ]
    }
   ],
   "source": [
    "history = nn_clf.fit(X_train, y_train_bin, epochs=100, batch_size=32, verbose=2, validation_data=(X_val, y_val_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      0.98      0.99       194\n",
      "        2.0       0.86      1.00      0.92        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.99      0.97      0.98        95\n",
      "        2.0       0.80      0.89      0.84         9\n",
      "        3.0       0.95      1.00      0.97        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.97      0.98      0.98        62\n",
      "        6.0       1.00      0.99      1.00       348\n",
      "        7.0       0.98      0.98      0.98        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(nn_clf, (X_train, X_val, y_train_num, y_val_num), \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(nn_clf, (X_train, X_val, y_train_bin, y_val_bin), 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = X_train_val_prepared_PCA.shape[-1]\n",
    "output_size = y_train_val.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_clf = Sequential()\n",
    "nn_clf.add(Dense(units=15, input_dim=number_of_features, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=15, activation='relu'))\n",
    "nn_clf.add(Dense(units=output_size, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 1,987\n",
      "Trainable params: 1,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 2s - loss: 0.3348 - acc: 0.8747\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1332 - acc: 0.9520\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0707 - acc: 0.9695\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0403 - acc: 0.9879\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0276 - acc: 0.9922\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0225 - acc: 0.9932\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0193 - acc: 0.9934\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0173 - acc: 0.9941\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0156 - acc: 0.9944\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0155 - acc: 0.9939\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0152 - acc: 0.9945\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0129 - acc: 0.9956\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0151 - acc: 0.9944\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0128 - acc: 0.9955\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0112 - acc: 0.9961\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0141 - acc: 0.9950\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0092 - acc: 0.9965\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0087 - acc: 0.9971\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0073 - acc: 0.9974\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0075 - acc: 0.9973\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0072 - acc: 0.9974\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0061 - acc: 0.9976\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0070 - acc: 0.9974\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0077 - acc: 0.9973\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0071 - acc: 0.9974\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0064 - acc: 0.9974\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0062 - acc: 0.9974\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0055 - acc: 0.9977\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0053 - acc: 0.9978\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0053 - acc: 0.9980\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0055 - acc: 0.9977\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0048 - acc: 0.9979\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0055 - acc: 0.9977\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0057 - acc: 0.9979\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0045 - acc: 0.9979\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0052 - acc: 0.9979\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0050 - acc: 0.9980\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0045 - acc: 0.9981\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0043 - acc: 0.9979\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0040 - acc: 0.9981\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0068 - acc: 0.9976\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0070 - acc: 0.9973\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0048 - acc: 0.9982\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0041 - acc: 0.9983\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0050 - acc: 0.9978\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0044 - acc: 0.9979\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0042 - acc: 0.9984\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0044 - acc: 0.9982\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0034 - acc: 0.9985\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0037 - acc: 0.9986\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0037 - acc: 0.9985\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0030 - acc: 0.9986\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0038 - acc: 0.9982\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0046 - acc: 0.9984\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0030 - acc: 0.9988\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0030 - acc: 0.9985\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0039 - acc: 0.9987\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0037 - acc: 0.9984\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0026 - acc: 0.9989\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0119 - acc: 0.9971\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0052 - acc: 0.9981\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0036 - acc: 0.9986\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0029 - acc: 0.9987\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0039 - acc: 0.9981\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0032 - acc: 0.9986\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0025 - acc: 0.9986\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0033 - acc: 0.9985\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0027 - acc: 0.9989\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0022 - acc: 0.9992\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0025 - acc: 0.9989\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0046 - acc: 0.9982\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0029 - acc: 0.9988\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0026 - acc: 0.9989\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0024 - acc: 0.9989\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0024 - acc: 0.9990\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0021 - acc: 0.9990\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0045 - acc: 0.9984\n"
     ]
    }
   ],
   "source": [
    "history = nn_clf.fit(X_train_val_prepared_PCA, y_train_val, epochs=100, batch_size=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      0.99      0.99       289\n",
      "        2.0       0.90      1.00      0.95        27\n",
      "        3.0       0.98      1.00      0.99       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       1.00      1.00      1.00       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.97      0.95       143\n",
      "        2.0       0.58      0.54      0.56        13\n",
      "        3.0       0.94      1.00      0.97        51\n",
      "        4.0       0.99      0.98      0.99       236\n",
      "        5.0       1.00      0.99      0.99        93\n",
      "        6.0       1.00      0.99      0.99       520\n",
      "        7.0       0.97      1.00      0.99        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(nn_clf, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794591077255936\n"
     ]
    }
   ],
   "source": [
    "print(get_f1_score_nn(nn_clf, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795191451469278\n"
     ]
    }
   ],
   "source": [
    "print(get_acc_score_nn(nn_clf, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.5\n",
      "53.85\n",
      "100.0\n",
      "98.31\n",
      "98.92\n",
      "98.65\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_acc_by_class(get_acc_by_class_nn(nn_clf, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf = KNeighborsClassifier(n_neighbors=10, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf = train_model(kNN_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: kNN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       194\n",
      "        2.0       1.00      1.00      1.00        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      1.00      0.97        95\n",
      "        2.0       1.00      0.44      0.62         9\n",
      "        3.0       0.95      1.00      0.97        35\n",
      "        4.0       1.00      0.99      0.99       158\n",
      "        5.0       0.98      0.98      0.98        62\n",
      "        6.0       1.00      0.99      1.00       348\n",
      "        7.0       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(kNN_clf, (X_train, X_val, y_train_num, y_val_num), \"kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       289\n",
      "        2.0       1.00      1.00      1.00        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       1.00      1.00      1.00       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.98      0.96       143\n",
      "        2.0       0.50      0.23      0.32        13\n",
      "        3.0       0.96      0.98      0.97        51\n",
      "        4.0       1.00      0.99      1.00       236\n",
      "        5.0       1.00      0.99      0.99        93\n",
      "        6.0       0.99      1.00      1.00       520\n",
      "        7.0       1.00      1.00      1.00        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n",
      "Model: KNN\n",
      "Weighted F1-score:  0.9819875308253083\n",
      "Accuracy:  0.9839715048975958\n",
      "97.9\n",
      "23.08\n",
      "98.04\n",
      "99.15\n",
      "98.92\n",
      "99.81\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Ada Boost regression\")\n",
    "print(\"Model: KNN\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(C=0.004, kernel='poly', degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = train_model(svm_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.98      0.99      0.99       194\n",
      "        2.0       0.94      0.83      0.88        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.97      0.99      0.98        95\n",
      "        2.0       0.86      0.67      0.75         9\n",
      "        3.0       1.00      1.00      1.00        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       1.00      0.97      0.98        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.98      0.98      0.98        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(svm_clf, (X_train, X_val, y_train_num, y_val_num), \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.99      1.00      0.99       289\n",
      "        2.0       0.96      0.85      0.90        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       1.00      1.00      1.00       188\n",
      "        6.0       1.00      1.00      1.00      1054\n",
      "        7.0       1.00      1.00      1.00       136\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.92      0.97      0.95       143\n",
      "        2.0       0.67      0.62      0.64        13\n",
      "        3.0       1.00      0.98      0.99        51\n",
      "        4.0       1.00      1.00      1.00       236\n",
      "        5.0       1.00      0.98      0.99        93\n",
      "        6.0       1.00      0.99      0.99       520\n",
      "        7.0       1.00      1.00      1.00        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n",
      "Model: SVM\n",
      "Weighted F1-score:  0.9839768618739583\n",
      "Accuracy:  0.9839715048975958\n",
      "97.2\n",
      "61.54\n",
      "98.04\n",
      "100.0\n",
      "97.85\n",
      "98.85\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C=0.004, kernel='poly', degree=2)\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Ada Boost regression\")\n",
    "print(\"Model: SVM\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978691597838611 (5, 300)\n"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0\n",
    "best_params = (0,0)\n",
    "\n",
    "for max_depth in range(2,6):\n",
    "    for n_estimators in range(200, 1600, 100):\n",
    "        random_forest_clf = ensemble.RandomForestClassifier(max_depth=max_depth, \n",
    "                                                            n_estimators=n_estimators, \n",
    "                                                            criterion='gini')\n",
    "        \n",
    "        random_forest_clf = train_model(random_forest_clf, (X_train, y_train_num))\n",
    "        #y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = random_forest_clf.predict(X_val)\n",
    "        curr_f1_score = metrics.f1_score(y_val_num, y_val_pred, average='weighted')\n",
    "        if curr_f1_score > best_f1_score:\n",
    "            best_f1_score = curr_f1_score\n",
    "            best_params = (max_depth, n_estimators)\n",
    "\n",
    "print(best_f1_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = ensemble.RandomForestClassifier(max_depth=5, n_estimators=300, criterion='gini', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = train_model(random_forest_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.98      0.96       194\n",
      "        2.0       1.00      0.28      0.43        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       0.99      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.91      0.99      0.95        95\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       1.00      1.00      1.00        35\n",
      "        4.0       1.00      0.99      1.00       158\n",
      "        5.0       0.98      0.98      0.98        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.97      0.98      0.98       752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(random_forest_clf, (X_train, X_val, y_train_num, y_val_num), \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest regression\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.92      0.98      0.95       289\n",
      "        2.0       1.00      0.15      0.26        27\n",
      "        3.0       1.00      1.00      1.00       105\n",
      "        4.0       1.00      1.00      1.00       479\n",
      "        5.0       0.98      1.00      0.99       188\n",
      "        6.0       0.99      1.00      1.00      1054\n",
      "        7.0       1.00      0.99      1.00       136\n",
      "\n",
      "avg / total       0.99      0.99      0.98      2278\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.98      0.96       143\n",
      "        2.0       1.00      0.08      0.14        13\n",
      "        3.0       1.00      0.98      0.99        51\n",
      "        4.0       1.00      0.99      0.99       236\n",
      "        5.0       0.99      0.98      0.98        93\n",
      "        6.0       0.98      1.00      0.99       520\n",
      "        7.0       1.00      1.00      1.00        67\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1123\n",
      "\n",
      "Model: Random Forest\n",
      "Weighted F1-score:  0.9759911411540331\n",
      "Accuracy:  0.9804096170970614\n",
      "97.9\n",
      "7.69\n",
      "98.04\n",
      "98.73\n",
      "97.85\n",
      "99.81\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(max_depth=5, n_estimators=300, criterion='gini', )\n",
    "model.fit(X_train_val_prepared_PCA, y_train_val_num)\n",
    "evaluate_model(model, (X_train_val_prepared_PCA, X_test_prepared_PCA, y_train_val_num, y_test_num), \"Random Forest regression\")\n",
    "print(\"Model: Random Forest\")\n",
    "print(\"Weighted F1-score: \", get_f1_score(model, X_test_prepared_PCA, y_test_num))\n",
    "print(\"Accuracy: \", get_acc_score(model, X_test_prepared_PCA, y_test_num))\n",
    "\n",
    "print_acc_by_class(get_acc_by_class(model, X_test_prepared_PCA, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
