{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_precision = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_muris_path = \"../datasets/tabula_muris_whole/\"\n",
    "all_counts_path = \"brain_mouse_matrix_all_counts.csv\"\n",
    "all_data_path = \"brain_mouse_matrix_all_data.csv\"\n",
    "all_scaled_path = \"brain_mouse_matrix_all_scale_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = pd.read_csv(tabula_muris_path + all_counts_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data =  pd.read_csv(tabula_muris_path + all_data_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scaled =  pd.read_csv(tabula_muris_path + all_scaled_path, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_ID</th>\n",
       "      <th>0610005C13Rik</th>\n",
       "      <th>0610007C21Rik</th>\n",
       "      <th>0610007L01Rik</th>\n",
       "      <th>0610007N19Rik</th>\n",
       "      <th>0610007P08Rik</th>\n",
       "      <th>0610007P14Rik</th>\n",
       "      <th>0610007P22Rik</th>\n",
       "      <th>0610008F07Rik</th>\n",
       "      <th>0610009B14Rik</th>\n",
       "      <th>...</th>\n",
       "      <th>Zxdc</th>\n",
       "      <th>Zyg11a</th>\n",
       "      <th>Zyg11b</th>\n",
       "      <th>Zyx</th>\n",
       "      <th>Zzef1</th>\n",
       "      <th>Zzz3</th>\n",
       "      <th>a</th>\n",
       "      <th>l7Rn6</th>\n",
       "      <th>zsGreen-transgene</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1.B003290.3_38_F.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1.B003728.3_56_F.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1.MAA000560.3_10_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1.MAA000564.3_10_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1.MAA000923.3_9_M.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CELL_ID  0610005C13Rik  0610007C21Rik  0610007L01Rik  \\\n",
       "0    A1.B003290.3_38_F.1.1              0            125             16   \n",
       "1    A1.B003728.3_56_F.1.1              0              0              0   \n",
       "2  A1.MAA000560.3_10_M.1.1              0            348              0   \n",
       "3  A1.MAA000564.3_10_M.1.1              0             41             36   \n",
       "4   A1.MAA000923.3_9_M.1.1              0             53              0   \n",
       "\n",
       "   0610007N19Rik  0610007P08Rik  0610007P14Rik  0610007P22Rik  0610008F07Rik  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0            324              0              0   \n",
       "2              0              0              5              0              0   \n",
       "3              0              0             24              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   0610009B14Rik  ...  Zxdc  Zyg11a  Zyg11b  Zyx  Zzef1  Zzz3  a  l7Rn6  \\\n",
       "0              0  ...     0       0       0    0      0     0  0     54   \n",
       "1              0  ...     0       0       0    0      0     0  0      0   \n",
       "2              0  ...     0       0       0    0    195     0  0    113   \n",
       "3              0  ...     0       0       0  125      0     1  0      0   \n",
       "4              0  ...     0       0      81    0      0     0  0      0   \n",
       "\n",
       "   zsGreen-transgene  annotation  \n",
       "0                  0           1  \n",
       "1                  0           1  \n",
       "2                  0           6  \n",
       "3                  0           4  \n",
       "4                  0           1  \n",
       "\n",
       "[5 rows x 23343 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normalize_data(data, scale=1000000.0):\n",
    "    data_row_sums = np.sum(data, axis=1).reshape(-1, 1)\n",
    "    return np.log(1 + scale * data / data_row_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "- one hot encoding of y\n",
    "- Log normalize all data\n",
    "- Split test and train data (stratified by y)\n",
    "- Scale data by normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_counts.iloc[:,1:-1].to_numpy(dtype=type_precision)\n",
    "y_num = all_counts.iloc[:, -1].to_numpy(dtype=type_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBin = preprocessing.LabelBinarizer()\n",
    "labelBin.fit(y_num)\n",
    "y = labelBin.transform(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = log_normalize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = model_selection.train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction #1 - PCA\n",
    "- TODO: pick different number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train_val)\n",
    "X_train_val_prepared_PCA = pca.transform(X_train_val)\n",
    "X_test_prepared_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: 0.14787763357162476\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance: {}\".format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2278, 12), (1123, 12))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val_prepared_PCA.shape, X_test_prepared_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction #2 - Autoencoder\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "- models: gradient boosting, NN, kNN(k=30 za pocetak), SVM, random forest \n",
    "- clean data\n",
    "- pick dimension reduction method\n",
    "- pick model\n",
    "- split train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data):\n",
    "    X_train, y_train = data\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, name):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print('Model: {}'.format(name))\n",
    "    print('Train set report: \\n{}'.format(metrics.classification_report(y_train, y_train_pred)))\n",
    "    print('Validation set report: \\n{}'.format(metrics.classification_report(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(model, data, name):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    y_train_pred = np.argmax(model.predict(X_train), axis=1) + 1\n",
    "    y_val_pred = np.argmax(model.predict(X_val), axis=1) + 1\n",
    "    print('Model: {}'.format(name))\n",
    "    print('Train set report: \\n{}'.format(metrics.classification_report(y_train, y_train_pred)))\n",
    "    print('Validation set report: \\n{}'.format(metrics.classification_report(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_bin, y_val_bin = model_selection.train_test_split(X_train_val_prepared_PCA, y_train_val, test_size=0.33, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num = labelBin.inverse_transform(y_train_bin)\n",
    "y_val_num = labelBin.inverse_transform(y_val_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train/val shape:  (1526, 12) (752, 12)\n",
      "y encoded train/val shape:  (1526, 7) (752, 7)\n",
      "y train/val shape:  (1526,) (752,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train/val shape: \", X_train.shape, X_val.shape)\n",
    "print(\"y encoded train/val shape: \", y_train_bin.shape, y_val_bin.shape)\n",
    "print(\"y train/val shape: \", y_train_num.shape, y_val_num.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_clf = ensemble.GradientBoostingClassifier(n_estimators=600, max_depth=2, learning_rate=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_clf = train_model(grad_boost_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Grad Boost\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.98      0.99      0.98       194\n",
      "        2.0       1.00      0.78      0.88        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       0.99      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.92      0.98      0.95        95\n",
      "        2.0       0.67      0.22      0.33         9\n",
      "        3.0       0.97      0.97      0.97        35\n",
      "        4.0       0.99      0.97      0.98       158\n",
      "        5.0       0.98      0.98      0.98        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.96      1.00      0.98        45\n",
      "\n",
      "avg / total       0.97      0.98      0.97       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grad_boost_clf, (X_train, X_val, y_train_num, y_val_num), \"Grad Boost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an AdaBoosted decision tree\n",
    "ada_boost_clf = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2),\n",
    "                                            algorithm=\"SAMME\",\n",
    "                                            n_estimators=400,\n",
    "                                            learning_rate=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_clf = train_model(ada_boost_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ada Boost\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.96      0.94      0.95       194\n",
      "        2.0       0.48      0.61      0.54        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.91      0.95      0.93        95\n",
      "        2.0       0.38      0.33      0.35         9\n",
      "        3.0       0.97      0.97      0.97        35\n",
      "        4.0       1.00      0.97      0.99       158\n",
      "        5.0       1.00      1.00      1.00        62\n",
      "        6.0       1.00      0.99      1.00       348\n",
      "        7.0       0.96      1.00      0.98        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ada_boost_clf, (X_train, X_val, y_train_num, y_val_num), \"Ada Boost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - pip install xgboost\n",
    "## -- import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softprob', max_depth=3, n_estimators=650, learning_rate=0.045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = train_model(xgb_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: kNN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       194\n",
      "        2.0       1.00      1.00      1.00        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.94      0.97      0.95        95\n",
      "        2.0       0.60      0.33      0.43         9\n",
      "        3.0       1.00      1.00      1.00        35\n",
      "        4.0       1.00      0.97      0.99       158\n",
      "        5.0       0.98      1.00      0.99        62\n",
      "        6.0       0.99      0.99      0.99       348\n",
      "        7.0       0.96      1.00      0.98        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb_clf, (X_train, X_val, y_train_num, y_val_num), \"kNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = X_train.shape[-1]\n",
    "output_size = y_train_bin.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_clf = Sequential()\n",
    "nn_clf.add(Dense(units=30, input_dim=number_of_features, activation='relu'))\n",
    "nn_clf.add(Dense(units=100, activation='relu'))\n",
    "nn_clf.add(Dense(units=30, activation='relu'))\n",
    "nn_clf.add(Dense(units=output_size, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 217       \n",
      "=================================================================\n",
      "Total params: 6,737\n",
      "Trainable params: 6,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1526 samples, validate on 752 samples\n",
      "Epoch 1/40\n",
      " - 0s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0170 - val_acc: 0.9947\n",
      "Epoch 2/40\n",
      " - 0s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0165 - val_acc: 0.9943\n",
      "Epoch 3/40\n",
      " - 0s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0184 - val_acc: 0.9941\n",
      "Epoch 4/40\n",
      " - 0s - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0184 - val_acc: 0.9939\n",
      "Epoch 5/40\n",
      " - 0s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0180 - val_acc: 0.9945\n",
      "Epoch 6/40\n",
      " - 0s - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0171 - val_acc: 0.9947\n",
      "Epoch 7/40\n",
      " - 0s - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0163 - val_acc: 0.9947\n",
      "Epoch 8/40\n",
      " - 0s - loss: 0.0048 - acc: 0.9979 - val_loss: 0.0175 - val_acc: 0.9945\n",
      "Epoch 9/40\n",
      " - 0s - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0176 - val_acc: 0.9953\n",
      "Epoch 10/40\n",
      " - 0s - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0181 - val_acc: 0.9941\n",
      "Epoch 11/40\n",
      " - 0s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0164 - val_acc: 0.9949\n",
      "Epoch 12/40\n",
      " - 0s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0184 - val_acc: 0.9941\n",
      "Epoch 13/40\n",
      " - 0s - loss: 0.0044 - acc: 0.9981 - val_loss: 0.0164 - val_acc: 0.9953\n",
      "Epoch 14/40\n",
      " - 0s - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0168 - val_acc: 0.9937\n",
      "Epoch 15/40\n",
      " - 0s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 16/40\n",
      " - 0s - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0168 - val_acc: 0.9943\n",
      "Epoch 17/40\n",
      " - 0s - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0161 - val_acc: 0.9954\n",
      "Epoch 18/40\n",
      " - 0s - loss: 0.0037 - acc: 0.9985 - val_loss: 0.0177 - val_acc: 0.9947\n",
      "Epoch 19/40\n",
      " - 0s - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0177 - val_acc: 0.9947\n",
      "Epoch 20/40\n",
      " - 0s - loss: 0.0042 - acc: 0.9983 - val_loss: 0.0177 - val_acc: 0.9945\n",
      "Epoch 21/40\n",
      " - 0s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0164 - val_acc: 0.9954\n",
      "Epoch 22/40\n",
      " - 0s - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0164 - val_acc: 0.9954\n",
      "Epoch 23/40\n",
      " - 0s - loss: 0.0032 - acc: 0.9986 - val_loss: 0.0161 - val_acc: 0.9953\n",
      "Epoch 24/40\n",
      " - 0s - loss: 0.0025 - acc: 0.9989 - val_loss: 0.0160 - val_acc: 0.9953\n",
      "Epoch 25/40\n",
      " - 0s - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0191 - val_acc: 0.9939\n",
      "Epoch 26/40\n",
      " - 0s - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Epoch 27/40\n",
      " - 0s - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0159 - val_acc: 0.9943\n",
      "Epoch 28/40\n",
      " - 0s - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "Epoch 29/40\n",
      " - 0s - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0184 - val_acc: 0.9945\n",
      "Epoch 30/40\n",
      " - 0s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0212 - val_acc: 0.9937\n",
      "Epoch 31/40\n",
      " - 0s - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0209 - val_acc: 0.9941\n",
      "Epoch 32/40\n",
      " - 0s - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0186 - val_acc: 0.9954\n",
      "Epoch 33/40\n",
      " - 0s - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0168 - val_acc: 0.9953\n",
      "Epoch 34/40\n",
      " - 0s - loss: 0.0044 - acc: 0.9979 - val_loss: 0.0182 - val_acc: 0.9949\n",
      "Epoch 35/40\n",
      " - 0s - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0229 - val_acc: 0.9945\n",
      "Epoch 36/40\n",
      " - 0s - loss: 0.0031 - acc: 0.9988 - val_loss: 0.0159 - val_acc: 0.9949\n",
      "Epoch 37/40\n",
      " - 0s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0176 - val_acc: 0.9949\n",
      "Epoch 38/40\n",
      " - 0s - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0168 - val_acc: 0.9958\n",
      "Epoch 39/40\n",
      " - 0s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0175 - val_acc: 0.9956\n",
      "Epoch 40/40\n",
      " - 0s - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0164 - val_acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "history = nn_clf.fit(X_train, y_train_bin, epochs=40, batch_size=30, verbose=2, validation_data=(X_val, y_val_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00       194\n",
      "        2.0       1.00      1.00      1.00        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.97      0.97      0.97        95\n",
      "        2.0       0.67      0.67      0.67         9\n",
      "        3.0       1.00      0.97      0.99        35\n",
      "        4.0       1.00      0.99      1.00       158\n",
      "        5.0       0.98      1.00      0.99        62\n",
      "        6.0       0.99      1.00      1.00       348\n",
      "        7.0       1.00      1.00      1.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(nn_clf, (X_train, X_val, y_train_num, y_val_num), \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(nn_clf, (X_train, X_val, y_train_bin, y_val_bin), 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf = KNeighborsClassifier(n_neighbors=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf = train_model(kNN_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: kNN\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      0.99      0.97       194\n",
      "        2.0       1.00      0.44      0.62        18\n",
      "        3.0       0.99      1.00      0.99        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       0.98      0.99      0.98       126\n",
      "        6.0       1.00      0.99      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.97      0.95        95\n",
      "        2.0       0.50      0.33      0.40         9\n",
      "        3.0       0.97      1.00      0.99        35\n",
      "        4.0       1.00      0.99      0.99       158\n",
      "        5.0       1.00      1.00      1.00        62\n",
      "        6.0       1.00      1.00      1.00       348\n",
      "        7.0       1.00      1.00      1.00        45\n",
      "\n",
      "avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(kNN_clf, (X_train, X_val, y_train_num, y_val_num), \"kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(C=0.004, kernel='poly', degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = train_model(svm_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.98      1.00      0.99       194\n",
      "        2.0       1.00      0.78      0.88        18\n",
      "        3.0       1.00      1.00      1.00        70\n",
      "        4.0       1.00      1.00      1.00       321\n",
      "        5.0       1.00      1.00      1.00       126\n",
      "        6.0       1.00      1.00      1.00       706\n",
      "        7.0       1.00      1.00      1.00        91\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      0.97      0.96        95\n",
      "        2.0       0.75      0.67      0.71         9\n",
      "        3.0       1.00      1.00      1.00        35\n",
      "        4.0       0.99      0.99      0.99       158\n",
      "        5.0       0.98      0.98      0.98        62\n",
      "        6.0       1.00      1.00      1.00       348\n",
      "        7.0       1.00      1.00      1.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(svm_clf, (X_train, X_val, y_train_num, y_val_num), \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = ensemble.RandomForestClassifier(max_depth=2, n_estimators=200, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = train_model(random_forest_clf, (X_train, y_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Train set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.91      0.82      0.86       194\n",
      "        2.0       0.00      0.00      0.00        18\n",
      "        3.0       1.00      0.73      0.84        70\n",
      "        4.0       0.93      0.97      0.95       321\n",
      "        5.0       1.00      0.24      0.38       126\n",
      "        6.0       0.83      1.00      0.91       706\n",
      "        7.0       1.00      0.98      0.99        91\n",
      "\n",
      "avg / total       0.89      0.88      0.86      1526\n",
      "\n",
      "Validation set report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.92      0.80      0.85        95\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       1.00      0.63      0.77        35\n",
      "        4.0       0.93      0.97      0.95       158\n",
      "        5.0       1.00      0.29      0.45        62\n",
      "        6.0       0.83      1.00      0.90       348\n",
      "        7.0       0.98      1.00      0.99        45\n",
      "\n",
      "avg / total       0.88      0.88      0.86       752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rastko/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(random_forest_clf, (X_train, X_val, y_train_num, y_val_num), \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
